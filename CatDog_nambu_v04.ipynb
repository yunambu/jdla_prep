{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow.keras import models, layers\n",
    "from glob import glob # ファイルパスを一気に取得するためのライブラリ\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_filepath = glob('data/cat/*jpg') # * で全ての意味"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog_filepath = glob('data/dog/*jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def reset_seed(seed=0):\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    random.seed(seed) #　random関数のシードを固定\n",
    "    np.random.seed(seed) #numpyのシードを固定\n",
    "    tf.random.set_seed(seed) #tensorflowのシードを固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, t = [], []\n",
    "\n",
    "for filepath in dog_filepath:\n",
    "    img = Image.open(filepath)\n",
    "    x.append(np.array(img))\n",
    "    t.append(0)\n",
    "    \n",
    "for filepath in cat_filepath:\n",
    "    img = Image.open(filepath)\n",
    "    x.append(np.array(img))\n",
    "    t.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(x)/255\n",
    "t = np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 224, 224, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 150, 350, 150)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, t_train, t_val = train_test_split(x, t, test_size=0.3, random_state=0)\n",
    "len(x_train), len(x_val), len(t_train), len(t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 224, 224, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import models, layers\n",
    "# reset_seed(0)\n",
    "\n",
    "# model = models.Sequential()\n",
    "\n",
    "# for layer in resnet.layers:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "# model.add(resnet)\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Dense(100, activation='relu'))\n",
    "# model.add(layers.Dense(30, activation='relu'))\n",
    "# model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.Adam(0.005)\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#              optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(x_train, t_train,\n",
    "#                    batch_size=128,\n",
    "#                    epochs=30,\n",
    "#                    validation_data=(x_val, t_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame(history.history)\n",
    "# results[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter 11x11 --> Filter 5x5 --> Filter 3x3 *3 layers\n",
    "# Stride 4\n",
    "# BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `kernel_size` argument must be a tuple of 2 integers. Received: (3, 3, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-29ccc5ee4fdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model.add(layers.Conv2D(64, (3, 3, 3), activation='relu', strides=(1, 1), \n\u001b[0;32m----> 6\u001b[0;31m                         padding=(1, 1, 1, 1), input_shape=(224, 224, 3)))\n\u001b[0m\u001b[1;32m      7\u001b[0m model.add(layers.Conv2D(64, (3, 3, 64), activation='relu', strides=(1, 1),\n\u001b[1;32m      8\u001b[0m                         padding=(1, 1, 1, 1)))\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     self.kernel_size = conv_utils.normalize_tuple(\n\u001b[0;32m--> 126\u001b[0;31m         kernel_size, rank, 'kernel_size')\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'strides'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36mnormalize_tuple\u001b[0;34m(value, n, name)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       raise ValueError('The `' + name + '` argument must be a tuple of ' +\n\u001b[0;32m---> 77\u001b[0;31m                        str(n) + ' integers. Received: ' + str(value))\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msingle_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `kernel_size` argument must be a tuple of 2 integers. Received: (3, 3, 3)"
     ]
    }
   ],
   "source": [
    "reset_seed(0)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3, 3), activation='relu', strides=(1, 1), \n",
    "                        padding=(1, 1, 1, 1), input_shape=(224, 224, 3)))\n",
    "model.add(layers.Conv2D(64, (3, 3, 64), activation='relu', strides=(1, 1),\n",
    "                        padding=(1, 1, 1, 1)))\n",
    "model.add(layers.MaxPool2D((2, 2), padding=(0, 0, 0, 0)))\n",
    "model.add(layers.Conv2D(64, (3, 3, 64), activation='relu', strides=(1, 1), \n",
    "                        padding=(1, 1, 1, 1)))\n",
    "model.add(layers.Conv2D(64, (3, 3, 128), activation='relu', strides=(1, 1), \n",
    "                        padding=(1, 1, 1, 1)))\n",
    "model.add(layers.MaxPool2D((2, 2), padding=(0, 0, 0, 0)))\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu', strides=(2, 2)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(33, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350 samples, validate on 150 samples\n",
      "Epoch 1/30\n",
      "350/350 [==============================] - 5s 13ms/sample - loss: 0.9014 - accuracy: 0.5486 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
      "Epoch 2/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.7714 - accuracy: 0.5914 - val_loss: 0.7147 - val_accuracy: 0.4933\n",
      "Epoch 3/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.5382 - accuracy: 0.7143 - val_loss: 0.8495 - val_accuracy: 0.5067\n",
      "Epoch 4/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.3693 - accuracy: 0.8457 - val_loss: 1.0041 - val_accuracy: 0.5067\n",
      "Epoch 5/30\n",
      "350/350 [==============================] - 3s 7ms/sample - loss: 0.2992 - accuracy: 0.9143 - val_loss: 1.0858 - val_accuracy: 0.5067\n",
      "Epoch 6/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.2287 - accuracy: 0.9600 - val_loss: 1.1195 - val_accuracy: 0.5067\n",
      "Epoch 7/30\n",
      "350/350 [==============================] - 3s 7ms/sample - loss: 0.1754 - accuracy: 0.9771 - val_loss: 1.2293 - val_accuracy: 0.5067\n",
      "Epoch 8/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.1329 - accuracy: 0.9857 - val_loss: 1.3696 - val_accuracy: 0.5067\n",
      "Epoch 9/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.0974 - accuracy: 1.0000 - val_loss: 1.4414 - val_accuracy: 0.5067\n",
      "Epoch 10/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.0730 - accuracy: 1.0000 - val_loss: 1.5442 - val_accuracy: 0.5067\n",
      "Epoch 11/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.0559 - accuracy: 1.0000 - val_loss: 1.6315 - val_accuracy: 0.5067\n",
      "Epoch 12/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.0396 - accuracy: 1.0000 - val_loss: 1.6415 - val_accuracy: 0.5067\n",
      "Epoch 13/30\n",
      "350/350 [==============================] - 3s 7ms/sample - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.6227 - val_accuracy: 0.5067\n",
      "Epoch 14/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.0304 - accuracy: 1.0000 - val_loss: 1.5723 - val_accuracy: 0.5067\n",
      "Epoch 15/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.5202 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "350/350 [==============================] - 3s 7ms/sample - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.4667 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "350/350 [==============================] - 3s 7ms/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.4301 - val_accuracy: 0.4933\n",
      "Epoch 18/30\n",
      "350/350 [==============================] - 3s 7ms/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3746 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.3253 - val_accuracy: 0.4933\n",
      "Epoch 20/30\n",
      "350/350 [==============================] - 3s 7ms/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.2787 - val_accuracy: 0.4933\n",
      "Epoch 21/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.2399 - val_accuracy: 0.4933\n",
      "Epoch 22/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1855 - val_accuracy: 0.4733\n",
      "Epoch 23/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1456 - val_accuracy: 0.4667\n",
      "Epoch 24/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1052 - val_accuracy: 0.4867\n",
      "Epoch 25/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0867 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "350/350 [==============================] - 3s 7ms/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0622 - val_accuracy: 0.4933\n",
      "Epoch 27/30\n",
      "350/350 [==============================] - 3s 8ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0420 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0226 - val_accuracy: 0.4867\n",
      "Epoch 29/30\n",
      "350/350 [==============================] - 3s 7ms/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0067 - val_accuracy: 0.5067\n",
      "Epoch 30/30\n",
      "350/350 [==============================] - 2s 7ms/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.5267\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, t_train,\n",
    "                   batch_size=128,\n",
    "                   epochs=30,\n",
    "                   validation_data=(x_val, t_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
