{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力 --> 中間 (2 --> 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5217943 ,  0.6583959 , -0.57024777],\n",
       "       [ 0.36538967, -0.79678635,  1.02704232]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2行3列の重み\n",
    "# np.random.seed(1) # 乱数の固定\n",
    "W1 = np.random.randn(2, 3)\n",
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19623548,  0.20705791, -1.84892494])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = np.random.randn(3)\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3503479 ,  0.85316832],\n",
       "       [ 0.22583983,  1.13003154],\n",
       "       [-0.74818147,  1.41871142],\n",
       "       [ 1.13212835, -0.27425191],\n",
       "       [ 0.95480926,  0.35541417],\n",
       "       [-2.23927598,  0.84741264],\n",
       "       [-0.29101914,  0.69122913],\n",
       "       [ 1.84853431, -0.9061379 ],\n",
       "       [ 0.27826776,  1.29755557],\n",
       "       [-0.70214575,  0.01593935]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サンプル数: 10, 入力変数: 2\n",
    "x = np.random.randn(10, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02518306, -0.70340258, -0.77289987],\n",
       "       [ 0.9528191 , -0.54464378, -0.81711939],\n",
       "       [-0.42396032, -1.4159516 ,  0.03480055],\n",
       "       [ 1.81889313,  1.17096676, -2.77618694],\n",
       "       [ 1.77912344,  0.55251126, -2.02837741],\n",
       "       [-2.90184612, -1.94247904,  0.29834585],\n",
       "       [ 0.00593219, -0.53530984, -0.97305035],\n",
       "       [ 2.67823102,  2.14612363, -3.83368949],\n",
       "       [ 1.09381517, -0.64360631, -0.67496203],\n",
       "       [-0.86646184, -0.26793223, -1.4321575 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1 = np.dot(x, W1) + b1 # np.dot: 行列積\n",
    "u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): # xが来たら、sigmoidを計算\n",
    "    # sigmoid: 1/1 + e**-x\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49370457, 0.33105826, 0.31585214],\n",
       "       [0.72168177, 0.36710798, 0.30637548],\n",
       "       [0.39556947, 0.19529703, 0.50869926],\n",
       "       [0.86043326, 0.76331972, 0.05862464],\n",
       "       [0.85558859, 0.63471803, 0.11625552],\n",
       "       [0.05206238, 0.12537576, 0.5740381 ],\n",
       "       [0.50148304, 0.36927931, 0.27427292],\n",
       "       [0.93572982, 0.89530599, 0.02117173],\n",
       "       [0.74909946, 0.34443178, 0.33738665],\n",
       "       [0.29599105, 0.4334148 , 0.19276274]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(u1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    # relu: max(0, x)\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02518306, -0.70340258, -0.77289987],\n",
       "       [ 0.9528191 , -0.54464378, -0.81711939],\n",
       "       [-0.42396032, -1.4159516 ,  0.03480055],\n",
       "       [ 1.81889313,  1.17096676, -2.77618694],\n",
       "       [ 1.77912344,  0.55251126, -2.02837741],\n",
       "       [-2.90184612, -1.94247904,  0.29834585],\n",
       "       [ 0.00593219, -0.53530984, -0.97305035],\n",
       "       [ 2.67823102,  2.14612363, -3.83368949],\n",
       "       [ 1.09381517, -0.64360631, -0.67496203],\n",
       "       [-0.86646184, -0.26793223, -1.4321575 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        ],\n",
       "       [0.9528191 , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.03480055],\n",
       "       [1.81889313, 1.17096676, 0.        ],\n",
       "       [1.77912344, 0.55251126, 0.        ],\n",
       "       [0.        , 0.        , 0.29834585],\n",
       "       [0.00593219, 0.        , 0.        ],\n",
       "       [2.67823102, 2.14612363, 0.        ],\n",
       "       [1.09381517, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = relu(u1)\n",
    "z1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中間 --> 出力 (3 --> 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87578226,  0.73959343],\n",
       "       [ 0.61346464, -0.65481173],\n",
       "       [ 0.86474353,  0.59962514]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = np.random.randn(3, 2)\n",
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00459401, 1.8061573 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = np.random.randn(2)\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00459401, 1.8061573 ],\n",
       "       [1.83905607, 2.51085604],\n",
       "       [1.03468755, 1.82702458],\n",
       "       [3.31589504, 2.38463593],\n",
       "       [2.90166488, 2.76019445],\n",
       "       [1.26258665, 1.98505297],\n",
       "       [1.00978932, 1.81054471],\n",
       "       [4.66671218, 2.38165243],\n",
       "       [1.96253793, 2.61513581],\n",
       "       [1.00459401, 1.8061573 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u2 = np.dot(z1, W2) + b2\n",
    "u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x)) # 指数関数化\n",
    "    # np.max(): オーバーフローを防ぐために、x の入ってきた値の最大値を使う\n",
    "    return exp_x / np.sum(exp_x) # 分母は指数関数の合計値 --> オーバーフローのリスク有 (桁溢れ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30969122, 0.69030878])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(u2[0]) # 足したら1になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30969122, 0.69030878])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(u2[0]) # x - np.max(x) にしてもしなくてもsoftmaxの値は変わらない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30969122, 0.69030878])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = softmax(u2[0])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x): # 複数で入ってきた場合と1つで入ってきた場合で分ける必要がある\n",
    "    if x.ndim == 2: # 2次元で来た場合\n",
    "        x =   x - x.max(axis=1, keepdims=True) # 次元数を確保したまま持ってくる\n",
    "        x =   np.exp(x) # 1行上のxをexp(x)のxに持ってくる\n",
    "        x /= x.sum(axis=1, keepdims=True)\n",
    "    elif x.ndim == 1: # 1次元で来た場合\n",
    "        x = x - np.max(x)\n",
    "        x = np.exp(x) / np.sum(np.exp(x))\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30969122, 0.69030878])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(u2[0]) # elif部分を実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30969122, 0.69030878],\n",
       "       [0.33809391, 0.66190609],\n",
       "       [0.31166709, 0.68833291],\n",
       "       [0.71733066, 0.28266934],\n",
       "       [0.53530874, 0.46469126],\n",
       "       [0.32685011, 0.67314989],\n",
       "       [0.30986396, 0.69013604],\n",
       "       [0.90763211, 0.09236789],\n",
       "       [0.34240435, 0.65759565],\n",
       "       [0.30969122, 0.69030878]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(u2) # if部分を実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レイヤとしてまとめていく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 変数\n",
    "    - パラメータ (W, b, etc.) = params\n",
    "    - 勾配 (傾きの値) = grads\n",
    "- メソッド\n",
    "    - 順伝播 = forward\n",
    "    - 逆伝播 = backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine変換 (線形変換)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    # パラメータの初期化    \n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "    \n",
    "    # 順伝播\n",
    "    def forward(self, x):\n",
    "        W, b = self.params # __init__内で定義したparamsの値を持ってくる\n",
    "        out   = np.dot(x, W) + b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu関数 (非線形変換)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " class Relu:\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.params = [] # 空で初期化\n",
    "            \n",
    "        def forward(self, x):\n",
    "            return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = np.random.randn(2, 3)\n",
    "b1  = np.random.randn(3)\n",
    "\n",
    "W2 = np.random.randn(3, 2)\n",
    "b2  = np.random.randn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    # 重みの初期化(W, b)\n",
    "    def  __init__(self, n_in, n_hidden, n_out):\n",
    "            \n",
    "        # W, bの初期化\n",
    "        W1 = np.random.randn(n_in, n_hidden) # n_in: input部分、n_hidden: 隠れ層の部分\n",
    "        b1  = np.random.randn(n_hidden)\n",
    "        W2 = np.random.randn(n_hidden, n_out) # n_out: output部分\n",
    "        b2  = np.random.randn(n_out)\n",
    "        \n",
    "        # レイヤを全てまとめる\n",
    "        self.layers = [\n",
    "            Affine(W1, b1), # 線形変換\n",
    "            Relu(), # 非線形変換\n",
    "            Affine(W2, b2) # 線形変換\n",
    "        ]\n",
    "    \n",
    "        # パラメータもまとめる\n",
    "        self.params = [] # 空で定義\n",
    "        for layer in self.layers: # まとめたレイヤから1つずつ取り出す\n",
    "            self.params += layer.params\n",
    "\n",
    "    # 推論\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x) # レイヤから1つずつ取り出して、順伝播(Affine->Relu->Affine)を行って、xに入れる\n",
    "        return x # forが終わったらxを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15462106,  3.40226488,  0.7170476 ,  0.20729256],\n",
       "       [-0.38656063, -0.67547516,  0.93002315,  0.02151904],\n",
       "       [-0.05913063,  0.04459165, -0.99117541, -1.62564992],\n",
       "       [-0.00754244, -0.43010632, -0.66328061, -0.26531219],\n",
       "       [ 0.20280208,  0.27339508,  0.79701795,  2.77283373],\n",
       "       [ 1.33265762, -0.58770624,  0.43754993,  0.77678151],\n",
       "       [-0.80316974,  0.01657396,  0.17988655,  1.48730058],\n",
       "       [ 1.55973066,  0.14878533, -2.06498805,  0.87799089],\n",
       "       [ 0.8202454 ,  0.69270584,  0.53305263,  0.49669397],\n",
       "       [-1.44935834,  0.05087876,  0.07864556,  0.64758715]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(10, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = NN(4, 10, 3) # 入力層=4, 中間層=10, 出力層=3(分類)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.51739805,  1.08127908, -0.57164515],\n",
       "       [-5.60117271,  2.53928048, -0.55142402],\n",
       "       [-2.75920549, -2.06308259, -0.49264387],\n",
       "       [ 2.70474154,  3.59501835,  3.49244043],\n",
       "       [ 9.28905241,  3.01286985, 11.17094777],\n",
       "       [ 5.25914896, -0.23908296,  8.275765  ],\n",
       "       [ 4.90829939,  5.19781461,  5.79458245],\n",
       "       [25.2753704 ,  2.65826811, 15.96723505],\n",
       "       [-0.94978282, -0.02607315,  3.79430964],\n",
       "       [-1.47368341,  5.62179486,  1.47690855]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逆伝播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    # パラメータの初期化    \n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)] # 勾配の値。初期値は何もない\n",
    "        # np.zeros_like(): ()と同じ方の0で埋めた行列で初期化\n",
    "        self.x = None # 入ってきたxの形\n",
    "    \n",
    "    # 順伝播\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        W, b = self.params # __init__内で定義したparamsの値を持ってくる\n",
    "        out = np.dot(x, W) + b\n",
    "        return out\n",
    "    \n",
    "    # 逆伝播\n",
    "    def backward(self, dout): # dout: 後ろから入ってきた値\n",
    "        W, b  = self.params # W, bを使う\n",
    "        dx = np.dot(dout, W.T) # Chain rule\n",
    "        dW = np.dot(self.x.T, dout) # Chain rule\n",
    "        db = np.sum(dout, axis=0) # 前から戻ってきたものを合計する(repeat)。axisは縦横の方向を指定\n",
    "        \n",
    "        self.grads[0][...] = dW # np.zeros_like(W)のWの値\n",
    "        self.grads[1][...] = db # np.zeros_like(b)のbの値\n",
    "        # [...]: deep cope, メモリを固定した上でコピー。ない場合はshallow copy。...: 3点リーダー\n",
    "        \n",
    "        return dx # 入力を微分した値を返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 87-88 手書きのため後回し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.out = None # 「何が出力されたか」をインスタンス変数として保持する必要がある。\n",
    "        # --> Sigmoid関数は微分を計算する際に出力結果を用いるから\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x)) # 1 / 1 + e**-x\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout): # dout: 前からどんな微分の値が来たかを返すための引数\n",
    "        dx = dout * (1.0 - self.out) * self.out # (1 - y) * y\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmoid = Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.98201379, 0.04742587])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 4, -3])\n",
    "sigmoid.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19661193, 0.31498076, 0.07065082, 0.2258833 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dout = np.array([1, 3, 4, 5]) # 前の微分の結果\n",
    "sigmoid.backward(dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.x = None # 「入力値が正か負か」をインスタンス変数として保持する必要がある\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x # インスタン変数にまず入れる\n",
    "        return np.maximum(0, self.x)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return np.where(self.x > 0, dout, 0) # self.xが0よりも大きい場合、doutを出力。それ以外は0を出力        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 4, -3])\n",
    "dout = np.array([1, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relu = Relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu.backward(dout) # xの部分が正の部分についてはそのままdout返し、負の部分は0を返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax with Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size) # 1xtのサイズ\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    # 教師データがOne-Hot表現の場合 ([0, 0, 1], [0, 1, 0]など)\n",
    "    elif t.size == y.size:\n",
    "        t = t.argmax(axis=1) # One-Hot表現の1の部分のインデックスを取る。\n",
    "        # ex: [0, 0, 1] --> 2, [0, 1, 0] --> 1\n",
    "    \n",
    "    batch_size = y.shape[0] # yの個数分をバッチサイズとする\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "    # np.log: 対数関数, 1e-7: 少数計算の補填, / batch_size: 対数関数の総和の平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, x, t): # Lossを求めるため、xだけでなくtとの差を見るため引数として取る\n",
    "        # 実測値\n",
    "        self.t = t\n",
    "        # 予測値\n",
    "        self.y = softmax(x) # 入ってきたものをsoftmax関数をかける\n",
    "        \n",
    "        if self.t.size == self.y.size: # ラベルがOne-Hot表現の時\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "        loss = cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "    \n",
    "    # softmaxの逆伝播\n",
    "    def backward(self, dout=1): # 初期値としてdout=1とする\n",
    "        batch_size = self.t.shape[0]\n",
    "        \n",
    "        # 以下の計算については参考書等でチェック\n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD (確率的勾配降下法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \n",
    "    def __init__(self, lr=0.01): # lr: learning rate, lr=0.01: デフォルト値\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr * grads[i] # 同じ要素番号同士の勾配に学習係数を掛ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNの構造の改良"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    # 重みの初期化(W, b)\n",
    "    def  __init__(self, n_in, n_hidden, n_out):\n",
    "            \n",
    "        # W, bの初期化\n",
    "        W1 = 0.01 * np.random.randn(n_in, n_hidden) # Wが大きすぎる可能性があるため、あらかじめ0.01倍して小さなスケールで始める\n",
    "        b1  = np.zeros(n_hidden) # ゼロベクトルで始まることが多い\n",
    "        W2 = 0.01 * np.random.randn(n_hidden, n_out)\n",
    "        b2  = np.zeros(n_out)\n",
    "        \n",
    "        # レイヤを全てまとめる\n",
    "        self.layers = [\n",
    "            Affine(W1, b1), # 線形変換\n",
    "            # Relu(), # 非線形変換\n",
    "            Sigmoid(), # どちらでもOK\n",
    "            Affine(W2, b2) # 線形変換\n",
    "        ]\n",
    "        \n",
    "        # 準電波の計算とは別に損失関数のレイヤーを設置\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "    \n",
    "        # パラメータもまとめる\n",
    "        self.params = [] # 空で定義\n",
    "        self.grads = [] # 勾配の値の定義を追加\n",
    "        for layer in self.layers: # まとめたレイヤから1つずつ取り出す\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    # 推論\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x) # レイヤから1つずつ取り出して、順伝播(Affine->Relu->Affine)を行って、xに入れる\n",
    "        return x # forが終わったらxを返す\n",
    "    \n",
    "    # 損失関数の計算 (順伝播)\n",
    "    def forward(self, x, t):\n",
    "        # 予測値の計算\n",
    "        y = self.predict(x)\n",
    "        loss = self.loss_layer.forward(y, t) # 損失関数の計算\n",
    "        return loss\n",
    "\n",
    "    # 損失関数の計算 (逆伝播)\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers): # 後ろから順にレイヤを取ってくる\n",
    "            dout = layer.backward(dout) # 2行上で定義したdoutを用いて逆伝播を開始\n",
    "        return dout\n",
    "    \n",
    "    # 精度\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1) # 最大値を抽出\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y==t) / float(len(x)) # yとtが同じものが何個あるかの平均\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備 (iris.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[:, :-1]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df.iloc[:, -1]\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  0  0\n",
       "1  1  0  0\n",
       "2  1  0  0\n",
       "3  1  0  0\n",
       "4  1  0  0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.get_dummies(t) # One-Hot表現(Dummy変数)に変換\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.values # pd --> np 変換\n",
    "t = t.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習に必要な準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 15\n",
    "n_hidden = 10 # 中間層のノードの数\n",
    "lr = 0.1 # 学習係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(t) # サンプル数の確認\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iters = N // batch_size # max iterations, // とすることで切り落としをして整数値を出力\n",
    "max_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(n_in=4, n_hidden=n_hidden, n_out=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | iter10/10 | loss1.105 |\n",
      "| epoch 2 | iter10/10 | loss1.104 |\n",
      "| epoch 3 | iter10/10 | loss1.101 |\n",
      "| epoch 4 | iter10/10 | loss1.103 |\n",
      "| epoch 5 | iter10/10 | loss1.103 |\n",
      "| epoch 6 | iter10/10 | loss1.101 |\n",
      "| epoch 7 | iter10/10 | loss1.105 |\n",
      "| epoch 8 | iter10/10 | loss1.099 |\n",
      "| epoch 9 | iter10/10 | loss1.092 |\n",
      "| epoch 10 | iter10/10 | loss1.091 |\n",
      "| epoch 11 | iter10/10 | loss1.08 |\n",
      "| epoch 12 | iter10/10 | loss1.065 |\n",
      "| epoch 13 | iter10/10 | loss1.05 |\n",
      "| epoch 14 | iter10/10 | loss1.024 |\n",
      "| epoch 15 | iter10/10 | loss0.995 |\n",
      "| epoch 16 | iter10/10 | loss0.959 |\n",
      "| epoch 17 | iter10/10 | loss0.917 |\n",
      "| epoch 18 | iter10/10 | loss0.87 |\n",
      "| epoch 19 | iter10/10 | loss0.823 |\n",
      "| epoch 20 | iter10/10 | loss0.773 |\n",
      "| epoch 21 | iter10/10 | loss0.729 |\n",
      "| epoch 22 | iter10/10 | loss0.69 |\n",
      "| epoch 23 | iter10/10 | loss0.654 |\n",
      "| epoch 24 | iter10/10 | loss0.626 |\n",
      "| epoch 25 | iter10/10 | loss0.599 |\n",
      "| epoch 26 | iter10/10 | loss0.577 |\n",
      "| epoch 27 | iter10/10 | loss0.559 |\n",
      "| epoch 28 | iter10/10 | loss0.542 |\n",
      "| epoch 29 | iter10/10 | loss0.526 |\n",
      "| epoch 30 | iter10/10 | loss0.515 |\n",
      "| epoch 31 | iter10/10 | loss0.503 |\n",
      "| epoch 32 | iter10/10 | loss0.493 |\n",
      "| epoch 33 | iter10/10 | loss0.483 |\n",
      "| epoch 34 | iter10/10 | loss0.474 |\n",
      "| epoch 35 | iter10/10 | loss0.465 |\n",
      "| epoch 36 | iter10/10 | loss0.455 |\n",
      "| epoch 37 | iter10/10 | loss0.451 |\n",
      "| epoch 38 | iter10/10 | loss0.439 |\n",
      "| epoch 39 | iter10/10 | loss0.433 |\n",
      "| epoch 40 | iter10/10 | loss0.424 |\n",
      "| epoch 41 | iter10/10 | loss0.42 |\n",
      "| epoch 42 | iter10/10 | loss0.411 |\n",
      "| epoch 43 | iter10/10 | loss0.407 |\n",
      "| epoch 44 | iter10/10 | loss0.398 |\n",
      "| epoch 45 | iter10/10 | loss0.394 |\n",
      "| epoch 46 | iter10/10 | loss0.385 |\n",
      "| epoch 47 | iter10/10 | loss0.38 |\n",
      "| epoch 48 | iter10/10 | loss0.375 |\n",
      "| epoch 49 | iter10/10 | loss0.367 |\n",
      "| epoch 50 | iter10/10 | loss0.364 |\n",
      "| epoch 51 | iter10/10 | loss0.357 |\n",
      "| epoch 52 | iter10/10 | loss0.349 |\n",
      "| epoch 53 | iter10/10 | loss0.34 |\n",
      "| epoch 54 | iter10/10 | loss0.337 |\n",
      "| epoch 55 | iter10/10 | loss0.328 |\n",
      "| epoch 56 | iter10/10 | loss0.325 |\n",
      "| epoch 57 | iter10/10 | loss0.322 |\n",
      "| epoch 58 | iter10/10 | loss0.312 |\n",
      "| epoch 59 | iter10/10 | loss0.309 |\n",
      "| epoch 60 | iter10/10 | loss0.307 |\n",
      "| epoch 61 | iter10/10 | loss0.295 |\n",
      "| epoch 62 | iter10/10 | loss0.294 |\n",
      "| epoch 63 | iter10/10 | loss0.287 |\n",
      "| epoch 64 | iter10/10 | loss0.279 |\n",
      "| epoch 65 | iter10/10 | loss0.276 |\n",
      "| epoch 66 | iter10/10 | loss0.284 |\n",
      "| epoch 67 | iter10/10 | loss0.265 |\n",
      "| epoch 68 | iter10/10 | loss0.261 |\n",
      "| epoch 69 | iter10/10 | loss0.26 |\n",
      "| epoch 70 | iter10/10 | loss0.254 |\n",
      "| epoch 71 | iter10/10 | loss0.257 |\n",
      "| epoch 72 | iter10/10 | loss0.245 |\n",
      "| epoch 73 | iter10/10 | loss0.251 |\n",
      "| epoch 74 | iter10/10 | loss0.242 |\n",
      "| epoch 75 | iter10/10 | loss0.235 |\n",
      "| epoch 76 | iter10/10 | loss0.234 |\n",
      "| epoch 77 | iter10/10 | loss0.23 |\n",
      "| epoch 78 | iter10/10 | loss0.222 |\n",
      "| epoch 79 | iter10/10 | loss0.216 |\n",
      "| epoch 80 | iter10/10 | loss0.229 |\n",
      "| epoch 81 | iter10/10 | loss0.222 |\n",
      "| epoch 82 | iter10/10 | loss0.211 |\n",
      "| epoch 83 | iter10/10 | loss0.211 |\n",
      "| epoch 84 | iter10/10 | loss0.204 |\n",
      "| epoch 85 | iter10/10 | loss0.202 |\n",
      "| epoch 86 | iter10/10 | loss0.208 |\n",
      "| epoch 87 | iter10/10 | loss0.207 |\n",
      "| epoch 88 | iter10/10 | loss0.194 |\n",
      "| epoch 89 | iter10/10 | loss0.193 |\n",
      "| epoch 90 | iter10/10 | loss0.195 |\n",
      "| epoch 91 | iter10/10 | loss0.187 |\n",
      "| epoch 92 | iter10/10 | loss0.191 |\n",
      "| epoch 93 | iter10/10 | loss0.186 |\n",
      "| epoch 94 | iter10/10 | loss0.181 |\n",
      "| epoch 95 | iter10/10 | loss0.183 |\n",
      "| epoch 96 | iter10/10 | loss0.173 |\n",
      "| epoch 97 | iter10/10 | loss0.187 |\n",
      "| epoch 98 | iter10/10 | loss0.176 |\n",
      "| epoch 99 | iter10/10 | loss0.171 |\n",
      "| epoch 100 | iter10/10 | loss0.17 |\n",
      "| epoch 101 | iter10/10 | loss0.167 |\n",
      "| epoch 102 | iter10/10 | loss0.172 |\n",
      "| epoch 103 | iter10/10 | loss0.16 |\n",
      "| epoch 104 | iter10/10 | loss0.171 |\n",
      "| epoch 105 | iter10/10 | loss0.163 |\n",
      "| epoch 106 | iter10/10 | loss0.161 |\n",
      "| epoch 107 | iter10/10 | loss0.157 |\n",
      "| epoch 108 | iter10/10 | loss0.157 |\n",
      "| epoch 109 | iter10/10 | loss0.161 |\n",
      "| epoch 110 | iter10/10 | loss0.156 |\n",
      "| epoch 111 | iter10/10 | loss0.148 |\n",
      "| epoch 112 | iter10/10 | loss0.158 |\n",
      "| epoch 113 | iter10/10 | loss0.148 |\n",
      "| epoch 114 | iter10/10 | loss0.145 |\n",
      "| epoch 115 | iter10/10 | loss0.161 |\n",
      "| epoch 116 | iter10/10 | loss0.149 |\n",
      "| epoch 117 | iter10/10 | loss0.154 |\n",
      "| epoch 118 | iter10/10 | loss0.146 |\n",
      "| epoch 119 | iter10/10 | loss0.149 |\n",
      "| epoch 120 | iter10/10 | loss0.149 |\n",
      "| epoch 121 | iter10/10 | loss0.139 |\n",
      "| epoch 122 | iter10/10 | loss0.139 |\n",
      "| epoch 123 | iter10/10 | loss0.147 |\n",
      "| epoch 124 | iter10/10 | loss0.141 |\n",
      "| epoch 125 | iter10/10 | loss0.133 |\n",
      "| epoch 126 | iter10/10 | loss0.137 |\n",
      "| epoch 127 | iter10/10 | loss0.144 |\n",
      "| epoch 128 | iter10/10 | loss0.141 |\n",
      "| epoch 129 | iter10/10 | loss0.128 |\n",
      "| epoch 130 | iter10/10 | loss0.137 |\n",
      "| epoch 131 | iter10/10 | loss0.134 |\n",
      "| epoch 132 | iter10/10 | loss0.126 |\n",
      "| epoch 133 | iter10/10 | loss0.14 |\n",
      "| epoch 134 | iter10/10 | loss0.125 |\n",
      "| epoch 135 | iter10/10 | loss0.135 |\n",
      "| epoch 136 | iter10/10 | loss0.125 |\n",
      "| epoch 137 | iter10/10 | loss0.13 |\n",
      "| epoch 138 | iter10/10 | loss0.129 |\n",
      "| epoch 139 | iter10/10 | loss0.129 |\n",
      "| epoch 140 | iter10/10 | loss0.12 |\n",
      "| epoch 141 | iter10/10 | loss0.122 |\n",
      "| epoch 142 | iter10/10 | loss0.118 |\n",
      "| epoch 143 | iter10/10 | loss0.129 |\n",
      "| epoch 144 | iter10/10 | loss0.123 |\n",
      "| epoch 145 | iter10/10 | loss0.134 |\n",
      "| epoch 146 | iter10/10 | loss0.122 |\n",
      "| epoch 147 | iter10/10 | loss0.115 |\n",
      "| epoch 148 | iter10/10 | loss0.122 |\n",
      "| epoch 149 | iter10/10 | loss0.132 |\n",
      "| epoch 150 | iter10/10 | loss0.115 |\n",
      "| epoch 151 | iter10/10 | loss0.123 |\n",
      "| epoch 152 | iter10/10 | loss0.118 |\n",
      "| epoch 153 | iter10/10 | loss0.111 |\n",
      "| epoch 154 | iter10/10 | loss0.13 |\n",
      "| epoch 155 | iter10/10 | loss0.112 |\n",
      "| epoch 156 | iter10/10 | loss0.108 |\n",
      "| epoch 157 | iter10/10 | loss0.11 |\n",
      "| epoch 158 | iter10/10 | loss0.119 |\n",
      "| epoch 159 | iter10/10 | loss0.116 |\n",
      "| epoch 160 | iter10/10 | loss0.112 |\n",
      "| epoch 161 | iter10/10 | loss0.116 |\n",
      "| epoch 162 | iter10/10 | loss0.118 |\n",
      "| epoch 163 | iter10/10 | loss0.103 |\n",
      "| epoch 164 | iter10/10 | loss0.112 |\n",
      "| epoch 165 | iter10/10 | loss0.11 |\n",
      "| epoch 166 | iter10/10 | loss0.106 |\n",
      "| epoch 167 | iter10/10 | loss0.109 |\n",
      "| epoch 168 | iter10/10 | loss0.105 |\n",
      "| epoch 169 | iter10/10 | loss0.103 |\n",
      "| epoch 170 | iter10/10 | loss0.114 |\n",
      "| epoch 171 | iter10/10 | loss0.106 |\n",
      "| epoch 172 | iter10/10 | loss0.106 |\n",
      "| epoch 173 | iter10/10 | loss0.104 |\n",
      "| epoch 174 | iter10/10 | loss0.097 |\n",
      "| epoch 175 | iter10/10 | loss0.125 |\n",
      "| epoch 176 | iter10/10 | loss0.108 |\n",
      "| epoch 177 | iter10/10 | loss0.103 |\n",
      "| epoch 178 | iter10/10 | loss0.1 |\n",
      "| epoch 179 | iter10/10 | loss0.105 |\n",
      "| epoch 180 | iter10/10 | loss0.116 |\n",
      "| epoch 181 | iter10/10 | loss0.104 |\n",
      "| epoch 182 | iter10/10 | loss0.102 |\n",
      "| epoch 183 | iter10/10 | loss0.108 |\n",
      "| epoch 184 | iter10/10 | loss0.107 |\n",
      "| epoch 185 | iter10/10 | loss0.103 |\n",
      "| epoch 186 | iter10/10 | loss0.099 |\n",
      "| epoch 187 | iter10/10 | loss0.111 |\n",
      "| epoch 188 | iter10/10 | loss0.102 |\n",
      "| epoch 189 | iter10/10 | loss0.101 |\n",
      "| epoch 190 | iter10/10 | loss0.096 |\n",
      "| epoch 191 | iter10/10 | loss0.095 |\n",
      "| epoch 192 | iter10/10 | loss0.098 |\n",
      "| epoch 193 | iter10/10 | loss0.097 |\n",
      "| epoch 194 | iter10/10 | loss0.105 |\n",
      "| epoch 195 | iter10/10 | loss0.095 |\n",
      "| epoch 196 | iter10/10 | loss0.094 |\n",
      "| epoch 197 | iter10/10 | loss0.095 |\n",
      "| epoch 198 | iter10/10 | loss0.094 |\n",
      "| epoch 199 | iter10/10 | loss0.098 |\n",
      "| epoch 200 | iter10/10 | loss0.095 |\n",
      "| epoch 201 | iter10/10 | loss0.101 |\n",
      "| epoch 202 | iter10/10 | loss0.099 |\n",
      "| epoch 203 | iter10/10 | loss0.101 |\n",
      "| epoch 204 | iter10/10 | loss0.104 |\n",
      "| epoch 205 | iter10/10 | loss0.101 |\n",
      "| epoch 206 | iter10/10 | loss0.103 |\n",
      "| epoch 207 | iter10/10 | loss0.108 |\n",
      "| epoch 208 | iter10/10 | loss0.092 |\n",
      "| epoch 209 | iter10/10 | loss0.113 |\n",
      "| epoch 210 | iter10/10 | loss0.091 |\n",
      "| epoch 211 | iter10/10 | loss0.092 |\n",
      "| epoch 212 | iter10/10 | loss0.097 |\n",
      "| epoch 213 | iter10/10 | loss0.097 |\n",
      "| epoch 214 | iter10/10 | loss0.093 |\n",
      "| epoch 215 | iter10/10 | loss0.089 |\n",
      "| epoch 216 | iter10/10 | loss0.087 |\n",
      "| epoch 217 | iter10/10 | loss0.082 |\n",
      "| epoch 218 | iter10/10 | loss0.082 |\n",
      "| epoch 219 | iter10/10 | loss0.092 |\n",
      "| epoch 220 | iter10/10 | loss0.092 |\n",
      "| epoch 221 | iter10/10 | loss0.109 |\n",
      "| epoch 222 | iter10/10 | loss0.088 |\n",
      "| epoch 223 | iter10/10 | loss0.092 |\n",
      "| epoch 224 | iter10/10 | loss0.093 |\n",
      "| epoch 225 | iter10/10 | loss0.086 |\n",
      "| epoch 226 | iter10/10 | loss0.097 |\n",
      "| epoch 227 | iter10/10 | loss0.094 |\n",
      "| epoch 228 | iter10/10 | loss0.098 |\n",
      "| epoch 229 | iter10/10 | loss0.086 |\n",
      "| epoch 230 | iter10/10 | loss0.095 |\n",
      "| epoch 231 | iter10/10 | loss0.093 |\n",
      "| epoch 232 | iter10/10 | loss0.091 |\n",
      "| epoch 233 | iter10/10 | loss0.087 |\n",
      "| epoch 234 | iter10/10 | loss0.094 |\n",
      "| epoch 235 | iter10/10 | loss0.094 |\n",
      "| epoch 236 | iter10/10 | loss0.088 |\n",
      "| epoch 237 | iter10/10 | loss0.099 |\n",
      "| epoch 238 | iter10/10 | loss0.095 |\n",
      "| epoch 239 | iter10/10 | loss0.085 |\n",
      "| epoch 240 | iter10/10 | loss0.091 |\n",
      "| epoch 241 | iter10/10 | loss0.084 |\n",
      "| epoch 242 | iter10/10 | loss0.095 |\n",
      "| epoch 243 | iter10/10 | loss0.091 |\n",
      "| epoch 244 | iter10/10 | loss0.085 |\n",
      "| epoch 245 | iter10/10 | loss0.091 |\n",
      "| epoch 246 | iter10/10 | loss0.085 |\n",
      "| epoch 247 | iter10/10 | loss0.086 |\n",
      "| epoch 248 | iter10/10 | loss0.083 |\n",
      "| epoch 249 | iter10/10 | loss0.091 |\n",
      "| epoch 250 | iter10/10 | loss0.088 |\n",
      "| epoch 251 | iter10/10 | loss0.103 |\n",
      "| epoch 252 | iter10/10 | loss0.083 |\n",
      "| epoch 253 | iter10/10 | loss0.09 |\n",
      "| epoch 254 | iter10/10 | loss0.081 |\n",
      "| epoch 255 | iter10/10 | loss0.086 |\n",
      "| epoch 256 | iter10/10 | loss0.081 |\n",
      "| epoch 257 | iter10/10 | loss0.081 |\n",
      "| epoch 258 | iter10/10 | loss0.088 |\n",
      "| epoch 259 | iter10/10 | loss0.089 |\n",
      "| epoch 260 | iter10/10 | loss0.091 |\n",
      "| epoch 261 | iter10/10 | loss0.086 |\n",
      "| epoch 262 | iter10/10 | loss0.086 |\n",
      "| epoch 263 | iter10/10 | loss0.083 |\n",
      "| epoch 264 | iter10/10 | loss0.083 |\n",
      "| epoch 265 | iter10/10 | loss0.084 |\n",
      "| epoch 266 | iter10/10 | loss0.079 |\n",
      "| epoch 267 | iter10/10 | loss0.082 |\n",
      "| epoch 268 | iter10/10 | loss0.086 |\n",
      "| epoch 269 | iter10/10 | loss0.088 |\n",
      "| epoch 270 | iter10/10 | loss0.082 |\n",
      "| epoch 271 | iter10/10 | loss0.082 |\n",
      "| epoch 272 | iter10/10 | loss0.079 |\n",
      "| epoch 273 | iter10/10 | loss0.086 |\n",
      "| epoch 274 | iter10/10 | loss0.08 |\n",
      "| epoch 275 | iter10/10 | loss0.086 |\n",
      "| epoch 276 | iter10/10 | loss0.083 |\n",
      "| epoch 277 | iter10/10 | loss0.104 |\n",
      "| epoch 278 | iter10/10 | loss0.088 |\n",
      "| epoch 279 | iter10/10 | loss0.077 |\n",
      "| epoch 280 | iter10/10 | loss0.094 |\n",
      "| epoch 281 | iter10/10 | loss0.087 |\n",
      "| epoch 282 | iter10/10 | loss0.079 |\n",
      "| epoch 283 | iter10/10 | loss0.078 |\n",
      "| epoch 284 | iter10/10 | loss0.087 |\n",
      "| epoch 285 | iter10/10 | loss0.103 |\n",
      "| epoch 286 | iter10/10 | loss0.087 |\n",
      "| epoch 287 | iter10/10 | loss0.084 |\n",
      "| epoch 288 | iter10/10 | loss0.077 |\n",
      "| epoch 289 | iter10/10 | loss0.098 |\n",
      "| epoch 290 | iter10/10 | loss0.088 |\n",
      "| epoch 291 | iter10/10 | loss0.081 |\n",
      "| epoch 292 | iter10/10 | loss0.083 |\n",
      "| epoch 293 | iter10/10 | loss0.09 |\n",
      "| epoch 294 | iter10/10 | loss0.089 |\n",
      "| epoch 295 | iter10/10 | loss0.08 |\n",
      "| epoch 296 | iter10/10 | loss0.089 |\n",
      "| epoch 297 | iter10/10 | loss0.082 |\n",
      "| epoch 298 | iter10/10 | loss0.086 |\n",
      "| epoch 299 | iter10/10 | loss0.09 |\n",
      "| epoch 300 | iter10/10 | loss0.078 |\n",
      "| epoch 301 | iter10/10 | loss0.079 |\n",
      "| epoch 302 | iter10/10 | loss0.08 |\n",
      "| epoch 303 | iter10/10 | loss0.079 |\n",
      "| epoch 304 | iter10/10 | loss0.095 |\n",
      "| epoch 305 | iter10/10 | loss0.08 |\n",
      "| epoch 306 | iter10/10 | loss0.082 |\n",
      "| epoch 307 | iter10/10 | loss0.082 |\n",
      "| epoch 308 | iter10/10 | loss0.078 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 309 | iter10/10 | loss0.088 |\n",
      "| epoch 310 | iter10/10 | loss0.08 |\n",
      "| epoch 311 | iter10/10 | loss0.079 |\n",
      "| epoch 312 | iter10/10 | loss0.08 |\n",
      "| epoch 313 | iter10/10 | loss0.084 |\n",
      "| epoch 314 | iter10/10 | loss0.082 |\n",
      "| epoch 315 | iter10/10 | loss0.078 |\n",
      "| epoch 316 | iter10/10 | loss0.083 |\n",
      "| epoch 317 | iter10/10 | loss0.077 |\n",
      "| epoch 318 | iter10/10 | loss0.081 |\n",
      "| epoch 319 | iter10/10 | loss0.095 |\n",
      "| epoch 320 | iter10/10 | loss0.081 |\n",
      "| epoch 321 | iter10/10 | loss0.079 |\n",
      "| epoch 322 | iter10/10 | loss0.083 |\n",
      "| epoch 323 | iter10/10 | loss0.083 |\n",
      "| epoch 324 | iter10/10 | loss0.08 |\n",
      "| epoch 325 | iter10/10 | loss0.078 |\n",
      "| epoch 326 | iter10/10 | loss0.084 |\n",
      "| epoch 327 | iter10/10 | loss0.077 |\n",
      "| epoch 328 | iter10/10 | loss0.071 |\n",
      "| epoch 329 | iter10/10 | loss0.075 |\n",
      "| epoch 330 | iter10/10 | loss0.081 |\n",
      "| epoch 331 | iter10/10 | loss0.078 |\n",
      "| epoch 332 | iter10/10 | loss0.077 |\n",
      "| epoch 333 | iter10/10 | loss0.075 |\n",
      "| epoch 334 | iter10/10 | loss0.088 |\n",
      "| epoch 335 | iter10/10 | loss0.077 |\n",
      "| epoch 336 | iter10/10 | loss0.073 |\n",
      "| epoch 337 | iter10/10 | loss0.077 |\n",
      "| epoch 338 | iter10/10 | loss0.074 |\n",
      "| epoch 339 | iter10/10 | loss0.078 |\n",
      "| epoch 340 | iter10/10 | loss0.075 |\n",
      "| epoch 341 | iter10/10 | loss0.074 |\n",
      "| epoch 342 | iter10/10 | loss0.073 |\n",
      "| epoch 343 | iter10/10 | loss0.073 |\n",
      "| epoch 344 | iter10/10 | loss0.088 |\n",
      "| epoch 345 | iter10/10 | loss0.075 |\n",
      "| epoch 346 | iter10/10 | loss0.077 |\n",
      "| epoch 347 | iter10/10 | loss0.076 |\n",
      "| epoch 348 | iter10/10 | loss0.077 |\n",
      "| epoch 349 | iter10/10 | loss0.066 |\n",
      "| epoch 350 | iter10/10 | loss0.072 |\n",
      "| epoch 351 | iter10/10 | loss0.08 |\n",
      "| epoch 352 | iter10/10 | loss0.078 |\n",
      "| epoch 353 | iter10/10 | loss0.08 |\n",
      "| epoch 354 | iter10/10 | loss0.079 |\n",
      "| epoch 355 | iter10/10 | loss0.072 |\n",
      "| epoch 356 | iter10/10 | loss0.073 |\n",
      "| epoch 357 | iter10/10 | loss0.077 |\n",
      "| epoch 358 | iter10/10 | loss0.075 |\n",
      "| epoch 359 | iter10/10 | loss0.099 |\n",
      "| epoch 360 | iter10/10 | loss0.068 |\n",
      "| epoch 361 | iter10/10 | loss0.076 |\n",
      "| epoch 362 | iter10/10 | loss0.074 |\n",
      "| epoch 363 | iter10/10 | loss0.079 |\n",
      "| epoch 364 | iter10/10 | loss0.075 |\n",
      "| epoch 365 | iter10/10 | loss0.082 |\n",
      "| epoch 366 | iter10/10 | loss0.086 |\n",
      "| epoch 367 | iter10/10 | loss0.071 |\n",
      "| epoch 368 | iter10/10 | loss0.069 |\n",
      "| epoch 369 | iter10/10 | loss0.081 |\n",
      "| epoch 370 | iter10/10 | loss0.08 |\n",
      "| epoch 371 | iter10/10 | loss0.094 |\n",
      "| epoch 372 | iter10/10 | loss0.074 |\n",
      "| epoch 373 | iter10/10 | loss0.077 |\n",
      "| epoch 374 | iter10/10 | loss0.075 |\n",
      "| epoch 375 | iter10/10 | loss0.078 |\n",
      "| epoch 376 | iter10/10 | loss0.082 |\n",
      "| epoch 377 | iter10/10 | loss0.073 |\n",
      "| epoch 378 | iter10/10 | loss0.086 |\n",
      "| epoch 379 | iter10/10 | loss0.075 |\n",
      "| epoch 380 | iter10/10 | loss0.082 |\n",
      "| epoch 381 | iter10/10 | loss0.069 |\n",
      "| epoch 382 | iter10/10 | loss0.065 |\n",
      "| epoch 383 | iter10/10 | loss0.08 |\n",
      "| epoch 384 | iter10/10 | loss0.081 |\n",
      "| epoch 385 | iter10/10 | loss0.069 |\n",
      "| epoch 386 | iter10/10 | loss0.069 |\n",
      "| epoch 387 | iter10/10 | loss0.07 |\n",
      "| epoch 388 | iter10/10 | loss0.073 |\n",
      "| epoch 389 | iter10/10 | loss0.071 |\n",
      "| epoch 390 | iter10/10 | loss0.07 |\n",
      "| epoch 391 | iter10/10 | loss0.079 |\n",
      "| epoch 392 | iter10/10 | loss0.069 |\n",
      "| epoch 393 | iter10/10 | loss0.072 |\n",
      "| epoch 394 | iter10/10 | loss0.085 |\n",
      "| epoch 395 | iter10/10 | loss0.079 |\n",
      "| epoch 396 | iter10/10 | loss0.074 |\n",
      "| epoch 397 | iter10/10 | loss0.083 |\n",
      "| epoch 398 | iter10/10 | loss0.085 |\n",
      "| epoch 399 | iter10/10 | loss0.075 |\n",
      "| epoch 400 | iter10/10 | loss0.085 |\n",
      "| epoch 401 | iter10/10 | loss0.07 |\n",
      "| epoch 402 | iter10/10 | loss0.079 |\n",
      "| epoch 403 | iter10/10 | loss0.068 |\n",
      "| epoch 404 | iter10/10 | loss0.076 |\n",
      "| epoch 405 | iter10/10 | loss0.07 |\n",
      "| epoch 406 | iter10/10 | loss0.079 |\n",
      "| epoch 407 | iter10/10 | loss0.074 |\n",
      "| epoch 408 | iter10/10 | loss0.075 |\n",
      "| epoch 409 | iter10/10 | loss0.068 |\n",
      "| epoch 410 | iter10/10 | loss0.067 |\n",
      "| epoch 411 | iter10/10 | loss0.085 |\n",
      "| epoch 412 | iter10/10 | loss0.068 |\n",
      "| epoch 413 | iter10/10 | loss0.064 |\n",
      "| epoch 414 | iter10/10 | loss0.073 |\n",
      "| epoch 415 | iter10/10 | loss0.069 |\n",
      "| epoch 416 | iter10/10 | loss0.066 |\n",
      "| epoch 417 | iter10/10 | loss0.075 |\n",
      "| epoch 418 | iter10/10 | loss0.073 |\n",
      "| epoch 419 | iter10/10 | loss0.078 |\n",
      "| epoch 420 | iter10/10 | loss0.092 |\n",
      "| epoch 421 | iter10/10 | loss0.069 |\n",
      "| epoch 422 | iter10/10 | loss0.075 |\n",
      "| epoch 423 | iter10/10 | loss0.074 |\n",
      "| epoch 424 | iter10/10 | loss0.069 |\n",
      "| epoch 425 | iter10/10 | loss0.073 |\n",
      "| epoch 426 | iter10/10 | loss0.064 |\n",
      "| epoch 427 | iter10/10 | loss0.111 |\n",
      "| epoch 428 | iter10/10 | loss0.075 |\n",
      "| epoch 429 | iter10/10 | loss0.07 |\n",
      "| epoch 430 | iter10/10 | loss0.074 |\n",
      "| epoch 431 | iter10/10 | loss0.068 |\n",
      "| epoch 432 | iter10/10 | loss0.073 |\n",
      "| epoch 433 | iter10/10 | loss0.079 |\n",
      "| epoch 434 | iter10/10 | loss0.076 |\n",
      "| epoch 435 | iter10/10 | loss0.059 |\n",
      "| epoch 436 | iter10/10 | loss0.073 |\n",
      "| epoch 437 | iter10/10 | loss0.076 |\n",
      "| epoch 438 | iter10/10 | loss0.068 |\n",
      "| epoch 439 | iter10/10 | loss0.075 |\n",
      "| epoch 440 | iter10/10 | loss0.074 |\n",
      "| epoch 441 | iter10/10 | loss0.072 |\n",
      "| epoch 442 | iter10/10 | loss0.072 |\n",
      "| epoch 443 | iter10/10 | loss0.074 |\n",
      "| epoch 444 | iter10/10 | loss0.08 |\n",
      "| epoch 445 | iter10/10 | loss0.069 |\n",
      "| epoch 446 | iter10/10 | loss0.067 |\n",
      "| epoch 447 | iter10/10 | loss0.07 |\n",
      "| epoch 448 | iter10/10 | loss0.071 |\n",
      "| epoch 449 | iter10/10 | loss0.064 |\n",
      "| epoch 450 | iter10/10 | loss0.072 |\n",
      "| epoch 451 | iter10/10 | loss0.069 |\n",
      "| epoch 452 | iter10/10 | loss0.069 |\n",
      "| epoch 453 | iter10/10 | loss0.073 |\n",
      "| epoch 454 | iter10/10 | loss0.077 |\n",
      "| epoch 455 | iter10/10 | loss0.07 |\n",
      "| epoch 456 | iter10/10 | loss0.072 |\n",
      "| epoch 457 | iter10/10 | loss0.068 |\n",
      "| epoch 458 | iter10/10 | loss0.065 |\n",
      "| epoch 459 | iter10/10 | loss0.074 |\n",
      "| epoch 460 | iter10/10 | loss0.072 |\n",
      "| epoch 461 | iter10/10 | loss0.065 |\n",
      "| epoch 462 | iter10/10 | loss0.077 |\n",
      "| epoch 463 | iter10/10 | loss0.063 |\n",
      "| epoch 464 | iter10/10 | loss0.071 |\n",
      "| epoch 465 | iter10/10 | loss0.073 |\n",
      "| epoch 466 | iter10/10 | loss0.07 |\n",
      "| epoch 467 | iter10/10 | loss0.07 |\n",
      "| epoch 468 | iter10/10 | loss0.069 |\n",
      "| epoch 469 | iter10/10 | loss0.069 |\n",
      "| epoch 470 | iter10/10 | loss0.08 |\n",
      "| epoch 471 | iter10/10 | loss0.069 |\n",
      "| epoch 472 | iter10/10 | loss0.069 |\n",
      "| epoch 473 | iter10/10 | loss0.076 |\n",
      "| epoch 474 | iter10/10 | loss0.074 |\n",
      "| epoch 475 | iter10/10 | loss0.086 |\n",
      "| epoch 476 | iter10/10 | loss0.068 |\n",
      "| epoch 477 | iter10/10 | loss0.066 |\n",
      "| epoch 478 | iter10/10 | loss0.071 |\n",
      "| epoch 479 | iter10/10 | loss0.076 |\n",
      "| epoch 480 | iter10/10 | loss0.066 |\n",
      "| epoch 481 | iter10/10 | loss0.073 |\n",
      "| epoch 482 | iter10/10 | loss0.072 |\n",
      "| epoch 483 | iter10/10 | loss0.066 |\n",
      "| epoch 484 | iter10/10 | loss0.07 |\n",
      "| epoch 485 | iter10/10 | loss0.067 |\n",
      "| epoch 486 | iter10/10 | loss0.062 |\n",
      "| epoch 487 | iter10/10 | loss0.069 |\n",
      "| epoch 488 | iter10/10 | loss0.066 |\n",
      "| epoch 489 | iter10/10 | loss0.08 |\n",
      "| epoch 490 | iter10/10 | loss0.062 |\n",
      "| epoch 491 | iter10/10 | loss0.081 |\n",
      "| epoch 492 | iter10/10 | loss0.071 |\n",
      "| epoch 493 | iter10/10 | loss0.066 |\n",
      "| epoch 494 | iter10/10 | loss0.061 |\n",
      "| epoch 495 | iter10/10 | loss0.072 |\n",
      "| epoch 496 | iter10/10 | loss0.079 |\n",
      "| epoch 497 | iter10/10 | loss0.073 |\n",
      "| epoch 498 | iter10/10 | loss0.06 |\n",
      "| epoch 499 | iter10/10 | loss0.068 |\n",
      "| epoch 500 | iter10/10 | loss0.07 |\n"
     ]
    }
   ],
   "source": [
    "losses = [] # 先々の損失関数をため込んでおくためのハコ\n",
    "total_loss, loss_count = 0, 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    index = np.random.permutation(N) # permutationメソッドを使って、インデックス番号をシャッフル\n",
    "    x = x[index]\n",
    "    t = t[index]\n",
    "    \n",
    "    for iters in range(max_iters):\n",
    "        batch_x = x[iters*batch_size: (iters+1)*batch_size] # 15刻みで前から取る\n",
    "        batch_t = t[iters*batch_size: (iters+1)*batch_size]\n",
    "        \n",
    "        # 順伝播\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        # 勾配を求める\n",
    "        model.backward()\n",
    "        # 現在のパラメータの値と購買情報を渡し、SGDを行う\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "        # 定期的い学習経過を出力\n",
    "        if (iters+1) % 10 == 0: # iters+1が10で割り切れるなら\n",
    "            aver_loss = total_loss / loss_count # 損失関数の平均を出す\n",
    "            print('| epoch {} | iter{}/{} | loss{} |'.format(epoch+1, iters+1, max_iters, round(aver_loss, 3)))\n",
    "            losses.append(aver_loss)\n",
    "            total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 44, 137, 144,  29, 104,  92, 116,  59,  80,  37, 136, 122,  13,\n",
       "        96, 126, 145,  22,  70, 108,   5, 138, 121,  19,  81,  33,  84,\n",
       "        10,  41,  11,  77,  40,  21,  49,   7, 143, 125,  24, 127,  79,\n",
       "       123,  67,  56, 147,  90,  32,  26, 141,  99, 112,  91,  60, 111,\n",
       "        94,  78,  20,  34, 119, 103, 110,  71, 114,  53,  23, 133,  73,\n",
       "       132,  68,  35, 128,  31, 115,  66, 118,  75,  83,  87, 129,  27,\n",
       "        46,  14,   1, 131, 113,  51,   9,   0,  65,   4, 135,  16, 134,\n",
       "        89, 105, 117,  18,  54, 101, 149,  52,   6,  50,  30,  42, 107,\n",
       "        88, 120, 106, 139,  58,   2,   3,  97,  55,  57, 130,  43,  76,\n",
       "        48,  17,  93,  38,  82,   8,  15, 100,  61,  98, 109,  45,  36,\n",
       "        85,  95,  64,  39, 142, 148,  47,  72,  69,  86, 140, 146,  74,\n",
       "        63, 124,  25,  12,  28, 102,  62])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(N) # 0-149 までのランダムの数値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.random.permutation(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3. , 1.6, 0.2],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters = 0\n",
    "x[iters*batch_size: (iters+1)*batch_size]\n",
    "# iters*batch_size = 0*15 = 0:\n",
    "# (iters+1)*batch_size = 1*15 = 15\n",
    "# 0 - 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.5, 3.2, 5.1, 2. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters = 1\n",
    "x[iters*batch_size: (iters+1)*batch_size]\n",
    "# iters*batch_size = 1*15 = 15:\n",
    "# (iters+1)*batch_size = 2*15 = 30\n",
    "# 15 - 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50e2a21ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5. , 3. , 1.6, 0.2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # 入力変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0] # 実測値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(x[0])\n",
    "y = np.argmax(softmax(y))\n",
    "y # index番号0番目が1となっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1,\n",
       "       2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 1, 2, 0, 0, 0, 1,\n",
       "       1, 1, 1, 2, 0, 0, 0, 2, 0, 1, 0, 0, 1, 2, 1, 1, 2, 2, 0, 2, 2, 2,\n",
       "       0, 2, 1, 0, 0, 2, 2, 1, 2, 1, 1, 0, 0, 0, 1, 0, 1, 2, 2, 2, 1, 1,\n",
       "       2, 0, 2, 0, 0, 2, 2, 1, 0, 2, 1, 1, 1, 2, 1, 0, 1, 1, 0, 2, 0, 1,\n",
       "       2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 1, 2, 2, 0, 1, 1, 0, 1,\n",
       "       2, 0, 0, 2, 2, 1, 0, 2, 1, 1, 0, 0, 1, 0, 2, 2, 0, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(x)\n",
    "y = np.argmax(softmax(y), axis=1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データ、テストデータを分けて実践してみると尚良し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
